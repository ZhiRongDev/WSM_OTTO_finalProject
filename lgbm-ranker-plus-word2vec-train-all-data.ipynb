{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b321b097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T02:32:31.606555Z",
     "iopub.status.busy": "2023-01-02T02:32:31.605030Z",
     "iopub.status.idle": "2023-01-02T03:24:35.666095Z",
     "shell.execute_reply": "2023-01-02T03:24:35.664775Z"
    },
    "papermill": {
     "duration": 3124.07184,
     "end_time": "2023-01-02T03:24:35.670949",
     "exception": false,
     "start_time": "2023-01-02T02:32:31.599109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polars\r\n",
      "  Downloading polars-0.15.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from polars) (4.4.0)\r\n",
      "Installing collected packages: polars\r\n",
      "Successfully installed polars-0.15.10\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mstart\n",
      "w2vec start\n",
      "w2vec end\n",
      "執行時間: 2179.835227251053 秒\n",
      "\n",
      "candidate calc start\n",
      "candidates\n",
      "shape: (36025020, 2)\n",
      "┌──────────┬─────────┐\n",
      "│ session  ┆ aid     │\n",
      "│ ---      ┆ ---     │\n",
      "│ i32      ┆ i32     │\n",
      "╞══════════╪═════════╡\n",
      "│ 11098528 ┆ 11830   │\n",
      "│ 11098528 ┆ 1732105 │\n",
      "│ 11098528 ┆ 588923  │\n",
      "│ 11098528 ┆ 884502  │\n",
      "│ ...      ┆ ...     │\n",
      "│ 12899778 ┆ 1727713 │\n",
      "│ 12899778 ┆ 1091487 │\n",
      "│ 12899778 ┆ 1552567 │\n",
      "│ 12899778 ┆ 588931  │\n",
      "└──────────┴─────────┘\n",
      "candidate calc end\n",
      "執行時間: 201.45789623260498 秒\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate calc start\n",
      "candidates\n",
      "shape: (33436060, 2)\n",
      "┌──────────┬─────────┐\n",
      "│ session  ┆ aid     │\n",
      "│ ---      ┆ ---     │\n",
      "│ i32      ┆ i32     │\n",
      "╞══════════╪═════════╡\n",
      "│ 12899779 ┆ 59625   │\n",
      "│ 12899779 ┆ 854602  │\n",
      "│ 12899779 ┆ 47723   │\n",
      "│ 12899779 ┆ 1738334 │\n",
      "│ ...      ┆ ...     │\n",
      "│ 14571581 ┆ 1514041 │\n",
      "│ 14571581 ┆ 1556465 │\n",
      "│ 14571581 ┆ 1621873 │\n",
      "│ 14571581 ┆ 1441424 │\n",
      "└──────────┴─────────┘\n",
      "candidate calc end\n",
      "執行時間: 180.93797874450684 秒\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install polars\n",
    "# !pip install nvtabular==1.3.3 merlin-models polars merlin-core==v0.4.0 dask_cuda\n",
    "\n",
    "print(\"start\")\n",
    "\n",
    "import time\n",
    "import gc\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "# import cudf\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "all_train = pl.read_parquet('/kaggle/input/otto-full-optimized-memory-footprint/train.parquet')\n",
    "test = pl.read_parquet('/kaggle/input/otto-full-optimized-memory-footprint/test.parquet')\n",
    "\n",
    "# train = pl.read_parquet('/kaggle/input/small-data/train.parquet')\n",
    "# test = pl.read_parquet('/kaggle/input/small-data/test.parquet')\n",
    "\n",
    "all_train = all_train.with_columns([\n",
    "    pl.col('session').cast(pl.datatypes.Int32),\n",
    "    pl.col('type').cast(pl.datatypes.UInt8),\n",
    "    pl.col('aid').cast(pl.datatypes.Int32),\n",
    "    pl.col('ts').cast(pl.datatypes.Int64)\n",
    "])\n",
    "\n",
    "test = test.with_columns([\n",
    "    pl.col('session').cast(pl.datatypes.Int32),\n",
    "    pl.col('type').cast(pl.datatypes.UInt8),\n",
    "    pl.col('aid').cast(pl.datatypes.Int32),\n",
    "    pl.col('ts').cast(pl.datatypes.Int64)\n",
    "])\n",
    "\n",
    "##### for Word2Vec pretrain\n",
    "sentences_df = pl.concat([all_train, test]).groupby('session').agg(\n",
    "    pl.col('aid').alias('sentence')\n",
    ")\n",
    "\n",
    "sentences = sentences_df['sentence'].to_list()\n",
    "\n",
    "del all_train\n",
    "gc.collect()\n",
    "\n",
    "train = pl.read_parquet('/kaggle/input/otto-train-and-test-data-for-local-validation/test.parquet')\n",
    "\n",
    "train = train.with_columns([\n",
    "    pl.col('session').cast(pl.datatypes.Int32),\n",
    "    pl.col('type').cast(pl.datatypes.UInt8),\n",
    "    pl.col('aid').cast(pl.datatypes.Int32),\n",
    "    pl.col('ts').cast(pl.datatypes.Int64)\n",
    "])\n",
    "\n",
    "print(\"w2vec start\")\n",
    "start = time.time()\n",
    "\n",
    "w2vec = Word2Vec(sentences=sentences, vector_size=32, min_count=1, workers=4)\n",
    "\n",
    "print(\"w2vec end\")\n",
    "end = time.time()\n",
    "print(f'執行時間: {end - start} 秒\\n')\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "aid2idx = {aid: i for i, aid in enumerate(w2vec.wv.index_to_key)}\n",
    "index = AnnoyIndex(32, 'euclidean')\n",
    "\n",
    "for aid, idx in aid2idx.items():\n",
    "    index.add_item(idx, w2vec.wv.vectors[idx])\n",
    "    \n",
    "index.build(10)\n",
    "#####\n",
    "\n",
    "###\n",
    "train_labels = pl.read_parquet('/kaggle/input/otto-train-and-test-data-for-local-validation/test_labels.parquet')\n",
    "\n",
    "def word2vec_candidate(df): \n",
    "    global index\n",
    "    session_types = ['clicks', 'carts', 'orders']\n",
    "    df_session_AIDs = df.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "    df_session_types = df.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "    df_session_num = df.to_pandas().reset_index(drop=True).groupby('session')['session'].apply(list)\n",
    "    \n",
    "    #\n",
    "    label_sessions = []\n",
    "    label_aids = []\n",
    "\n",
    "    print(\"candidate calc start\")\n",
    "    start = time.time()\n",
    "\n",
    "    type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "    for AIDs, types, session_num in zip(df_session_AIDs, df_session_types, df_session_num):\n",
    "        session_num = session_num[0]\n",
    "            \n",
    "        if len(AIDs) >= 20:\n",
    "            # if we have enough aids (over equals 20) we don't need to look for candidates! we just use the old logic\n",
    "            weights=np.logspace(0.1,1,len(AIDs),base=2, endpoint=True)-1\n",
    "            aids_temp=defaultdict(lambda: 0)\n",
    "            for aid,w,t in zip(AIDs,weights,types): \n",
    "                aids_temp[aid]+= w * type_weight_multipliers[t]\n",
    "                \n",
    "            sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n",
    "\n",
    "            if len(sorted_aids) < 20:\n",
    "                AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
    "                # let's grab the most recent aid\n",
    "                most_recent_aid = AIDs[0]\n",
    "                # and look for some neighbors!\n",
    "                nns = [w2vec.wv.index_to_key[i] for i in index.get_nns_by_item(aid2idx[most_recent_aid], 21)[1:]]\n",
    "                sorted_aids = (sorted_aids + nns)\n",
    "           \n",
    "            session_arr = [session_num for i in range(20)]\n",
    "            # \n",
    "            label_sessions.extend(session_arr)\n",
    "            label_aids.extend(sorted_aids[:20])\n",
    "\n",
    "        else:\n",
    "            # here we don't have 20 aids to output -- we will use word2vec embeddings to generate candidates!\n",
    "            AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
    "            # let's grab the most recent aid\n",
    "            most_recent_aid = AIDs[0]\n",
    "            # and look for some neighbors!\n",
    "            nns = [w2vec.wv.index_to_key[i] for i in index.get_nns_by_item(aid2idx[most_recent_aid], 21)[1:]]\n",
    "            \n",
    "            session_arr = [session_num for i in range(20)]\n",
    "            label_sessions.extend(session_arr)\n",
    "            label_aids.extend((AIDs+nns)[:20])  \n",
    "\n",
    "    candidates = pl.DataFrame({\"session\": label_sessions, \"aid\":label_aids})\n",
    "    candidates = candidates.with_columns([\n",
    "        pl.col('session').cast(pl.datatypes.Int32),\n",
    "        pl.col('aid').cast(pl.datatypes.Int32),\n",
    "    ])\n",
    "    \n",
    "    print('candidates')\n",
    "    print(candidates)\n",
    "    \n",
    "    print(\"candidate calc end\")\n",
    "    end = time.time()\n",
    "    print(f'執行時間: {end - start} 秒\\n')\n",
    "    \n",
    "    candidates = candidates.with_column(pl.col('aid').cumcount().over('session').alias('word2vec_rank') + 1)\n",
    "    candidates = candidates.with_columns([\n",
    "        pl.col('session').cast(pl.datatypes.Int32),\n",
    "    ])\n",
    "    \n",
    "    df = df.join(candidates, on=['session', 'aid'], how='outer').sort(\"session\")\n",
    "    return df\n",
    "\n",
    "def add_action_num_reverse_chrono(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.col('session').cumcount().reverse().over('session').alias('action_num_reverse_chrono')\n",
    "    ])\n",
    "\n",
    "def add_session_length(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.col('session').count().over('session').alias('session_length')\n",
    "    ])\n",
    "\n",
    "def add_log_recency_score(df):\n",
    "    linear_interpolation = 0.1 + ((1-0.1) / (df['session_length']-1)) * (df['session_length']-df['action_num_reverse_chrono']-1)\n",
    "    return df.with_columns(pl.Series(2**linear_interpolation - 1).alias('log_recency_score')).fill_nan(1)\n",
    "\n",
    "def add_type_weighted_log_recency_score(df):\n",
    "    type_weights = {0:1, 1:6, 2:3}\n",
    "    type_weighted_log_recency_score = pl.Series(df['log_recency_score'] / df['type'].apply(lambda x: type_weights[x]))\n",
    "    return df.with_column(type_weighted_log_recency_score.alias('type_weighted_log_recency_score'))\n",
    "\n",
    "def apply(df, pipeline):\n",
    "    for f in pipeline:\n",
    "        df = f(df)\n",
    "    return df\n",
    "\n",
    "pipeline = [add_action_num_reverse_chrono, add_session_length, add_log_recency_score, add_type_weighted_log_recency_score, word2vec_candidate]\n",
    "\n",
    "train = apply(train, pipeline)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "type2id = {\"clicks\": 0, \"carts\": 1, \"orders\": 2}\n",
    "\n",
    "train_labels = train_labels.explode('ground_truth').with_columns([\n",
    "    pl.col('ground_truth').alias('aid'),\n",
    "    pl.col('type').apply(lambda x: type2id[x])\n",
    "])[['session', 'type', 'aid']]\n",
    "\n",
    "train_labels = train_labels.with_columns([\n",
    "    pl.col('session').cast(pl.datatypes.Int32),\n",
    "    pl.col('type').cast(pl.datatypes.UInt8),\n",
    "    pl.col('aid').cast(pl.datatypes.Int32)\n",
    "])\n",
    "\n",
    "train_labels = train_labels.with_column(pl.lit(1).alias('gt'))\n",
    "\n",
    "train = train.join(train_labels, how='left', on=['session', 'type', 'aid']).with_column(pl.col('gt').fill_null(0))\n",
    "\n",
    "def get_session_lenghts(df):\n",
    "    return df.groupby('session').agg([\n",
    "        pl.col('session').count().alias('session_length')\n",
    "    ])['session_length'].to_numpy()\n",
    "\n",
    "session_lengths_train = get_session_lenghts(train)\n",
    "\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "\n",
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=20,\n",
    "    importance_type='gain',\n",
    ")\n",
    "\n",
    "feature_cols = ['aid', 'type', 'action_num_reverse_chrono', 'session_length', 'log_recency_score', 'type_weighted_log_recency_score', 'word2vec_rank']\n",
    "target = 'gt'\n",
    "\n",
    "ranker = ranker.fit(\n",
    "    train[feature_cols].to_pandas(),\n",
    "    train[target].to_pandas(),\n",
    "    group=session_lengths_train,\n",
    ")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "### create submission\n",
    "test = apply(test, pipeline)\n",
    "\n",
    "scores = ranker.predict(test[feature_cols].to_pandas())\n",
    "\n",
    "test = test.with_columns(pl.Series(name='score', values=scores))\n",
    "test_predictions = test.sort(['session', 'score'], reverse=True).groupby('session').agg([\n",
    "    pl.col('aid').limit(20).list()\n",
    "])\n",
    "\n",
    "session_types = []\n",
    "labels = []\n",
    "\n",
    "for session, preds in zip(test_predictions['session'].to_numpy(), test_predictions['aid'].to_numpy()):\n",
    "    l = ' '.join(str(p) for p in preds)\n",
    "    for session_type in ['clicks', 'carts', 'orders']:\n",
    "        labels.append(l)\n",
    "        session_types.append(f'{session}_{session_type}')\n",
    "\n",
    "submission = pl.DataFrame({'session_type': session_types, 'labels': labels})\n",
    "submission.write_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3138.124883,
   "end_time": "2023-01-02T03:24:39.914837",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-02T02:32:21.789954",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
